{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bc2919-f1e4-426f-9054-26e621901612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237df5c3-c6af-401e-9a9e-9b4e3876c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"combined_representations.npz\", allow_pickle=True)\n",
    "X_train_combined = data[\"X_train\"]\n",
    "X_val_combined = data[\"X_val\"]\n",
    "test_combined = data[\"test\"]\n",
    "y_train = data[\"y_train\"]\n",
    "y_val = data[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5686cd31-0d17-4786-9d2f-b837de19c505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'description': array([[ 0.        ,  0.        ,  0.        , ..., -0.26894767,\n",
       "         0.28410659, -0.05457572],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.18193519,\n",
       "         0.56684933,  0.1033013 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.15412894,\n",
       "         0.41844097, -0.1535055 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.20144454,\n",
       "         0.56314219, -0.01820332],\n",
       "       [ 0.        ,  0.        ,  0.11392692, ..., -0.09101021,\n",
       "         0.50645848,  0.04244453],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.29217856,\n",
       "         0.44455622,  0.144129  ]]), 'host_about': array([[ 0.        ,  0.        ,  0.        , ..., -0.12193654,\n",
       "        -0.0445922 , -0.00576038],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.1794887 ,\n",
       "         0.44336581,  0.22292026],\n",
       "       [ 0.        ,  0.08711945,  0.08898357, ..., -0.03605678,\n",
       "         0.48175168,  0.20329235],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.21277664,\n",
       "         0.22909964,  0.1939016 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.16944592,\n",
       "         0.31317102,  0.0449433 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.25649588,\n",
       "         0.346195  ,  0.22571714]]), 'comments': array([[ 0.00503341,  0.        ,  0.00571715, ..., -0.15276542,\n",
       "         0.26823887,  0.10006609],\n",
       "       [ 0.06032864,  0.        ,  0.        , ..., -0.1225307 ,\n",
       "         0.28384773,  0.01153072],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00669907,  0.        ,  0.01521815, ..., -0.36147214,\n",
       "         0.13623308,  0.1308486 ],\n",
       "       [ 0.14657201,  0.04839786,  0.        , ..., -0.04748795,\n",
       "         0.38492061,  0.08104253]])}, dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c57e753-24e6-4c7f-9c71-7e3fb930126a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'description': array([[ 0.        ,  0.        ,  0.        , ..., -0.28789246,\n",
       "         0.48497257,  0.15152374],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.06563767,\n",
       "         0.40370935,  0.0725085 ],\n",
       "       [ 0.        ,  0.        ,  0.1388047 , ..., -0.16953171,\n",
       "         0.3015066 ,  0.14860522],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.10403167,\n",
       "        -0.09614274,  0.04147864],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.16573102,\n",
       "         0.38612467,  0.25377321],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.121358  ,\n",
       "         0.53756869,  0.1067788 ]]), 'host_about': array([[ 0.        ,  0.        ,  0.        , ..., -0.36170898,\n",
       "         0.30741972,  0.08949168],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.11652934,\n",
       "         0.34135978,  0.214483  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.20559426,\n",
       "         0.22731568,  0.1786795 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.00849472,\n",
       "         0.0098264 , -0.0045921 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.13237719,\n",
       "         0.15893128,  0.11644312],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.03293796,\n",
       "         0.16548174,  0.02213182]]), 'comments': array([[ 0.01150267,  0.06267543,  0.        , ..., -0.26816061,\n",
       "         0.0866147 , -0.0186549 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.01230894,  0.0111781 ,  0.00461031, ..., -0.38538957,\n",
       "        -0.12799808, -0.01583558],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.0065324 , ..., -0.40341715,\n",
       "        -0.12195754,  0.05727574],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.03121314,  0.01214809,  0.01503112, ..., -0.33799594,\n",
       "         0.11315954,  0.17939468]])}, dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4637502c-e231-4774-8993-fd4c8191e286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'description': array([[ 0.        ,  0.        ,  0.        , ..., -0.18555058,\n",
       "         0.44161261, -0.0627408 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.0345583 ,\n",
       "         0.04763634, -0.02800948],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.08426904,\n",
       "         0.34936657,  0.0997809 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.21587891,\n",
       "         0.39432905,  0.11549282],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.23952458,\n",
       "         0.445471  ,  0.19499586],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.12781864,\n",
       "         0.43982258,  0.14028625]]), 'host_about': array([[ 0.        ,  0.        ,  0.        , ..., -0.28434646,\n",
       "        -0.07843604, -0.0471223 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.0291326 ,\n",
       "         0.04489934, -0.0054476 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.25649588,\n",
       "         0.346195  ,  0.22571714],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.13211228,\n",
       "         0.29305133,  0.14286702],\n",
       "       [ 0.11943162,  0.        ,  0.        , ..., -0.03605678,\n",
       "         0.48175168,  0.20329235],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.22638684,\n",
       "         0.37341186,  0.21335005]]), 'comments': array([[ 0.        ,  0.        ,  0.01388334, ..., -0.42094854,\n",
       "         0.27157354,  0.1565442 ],\n",
       "       [ 0.04310289,  0.        ,  0.        , ..., -0.26923792,\n",
       "         0.49961624,  0.25754154],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.01171436,  0.        ,  0.01320294, ..., -0.43070338,\n",
       "         0.05248512, -0.00060618],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.16405902,\n",
       "        -0.06260937, -0.05470258],\n",
       "       [ 0.02463455,  0.        ,  0.        , ..., -0.39168488,\n",
       "         0.03944418,  0.04972226]])}, dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8c433e-8492-43b8-85f2-44b34b39519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1562,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a07d76-e702-454b-b643-1560e7109963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4686,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512ba27-bdf7-4f69-b05b-f08380e4b533",
   "metadata": {},
   "source": [
    "### Preparing data for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f9eca1-d8b2-4b2d-80c5-c99b2e62e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged feature matrix: (4686, 1800)\n"
     ]
    }
   ],
   "source": [
    "# For X_train_combined\n",
    "\n",
    "train_dict = X_train_combined.item()\n",
    "\n",
    "description_features_train = train_dict['description']\n",
    "host_about_features_train = train_dict['host_about']\n",
    "comments_features_train = train_dict['comments']\n",
    "\n",
    "X_train_merged = np.concatenate((description_features_train, host_about_features_train, comments_features_train), axis=1)\n",
    "print(\"Shape of merged feature matrix:\", X_train_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c769012-d604-48d1-b852-1edec788bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged feature matrix: (1562, 1800)\n"
     ]
    }
   ],
   "source": [
    "# For X_val_combined\n",
    "\n",
    "val_dict = X_val_combined.item()\n",
    "\n",
    "description_features_val = val_dict['description']\n",
    "host_about_features_val = val_dict['host_about']\n",
    "comments_features_val = val_dict['comments']\n",
    "\n",
    "X_val_merged = np.concatenate((description_features_val, host_about_features_val, comments_features_val), axis=1)\n",
    "print(\"Shape of merged feature matrix:\", X_val_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bfb901-e737-4717-9883-9c742c0c1892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged feature matrix: (695, 1800)\n"
     ]
    }
   ],
   "source": [
    "# For test_combined\n",
    "\n",
    "test_dict = test_combined.item()\n",
    "\n",
    "description_features_test = test_dict['description']\n",
    "host_about_features_test = test_dict['host_about']\n",
    "comments_features_test = test_dict['comments']\n",
    "\n",
    "X_test_merged = np.concatenate((description_features_test, host_about_features_test, comments_features_test), axis=1)\n",
    "print(\"Shape of merged feature matrix:\", X_test_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb14b7-15ab-434d-9cf2-be878fa46060",
   "metadata": {},
   "source": [
    "# Models\n",
    "##### Grid Searches are small because that's not the main point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf433c9-1de5-4acb-8bb0-c42da7714461",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f39e3d2-4ea9-40ec-bade-29d7cdd22a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:29<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 0.005, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "F1 score on validation set with best parameters: 0.7266325224071702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      1135\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.73      1562\n",
      "   macro avg       0.36      0.50      0.42      1562\n",
      "weighted avg       0.53      0.73      0.61      1562\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1135    0]\n",
      " [ 427    0]]\n",
      "F1 score on validation set: 0.6115891085889048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define values for grid search\n",
    "parameters = {\n",
    "    'C': [0.005, 0.01, 0.05],  # Regularization\n",
    "    'penalty': ['l1', 'l2'],  \n",
    "    'solver': ['liblinear', 'saga'],  # Optimization     \n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar\n",
    "total_combinations = len(parameters['C']) * len(parameters['penalty']) * len(parameters['solver'])\n",
    "pbar = tqdm(total=total_combinations)\n",
    "\n",
    "# Iterate over all combinations of parameters\n",
    "for C, penalty, solver in product(parameters['C'], parameters['penalty'], parameters['solver']):\n",
    "\n",
    "    pbar.update(1)\n",
    "    lr = LogisticRegression(C=C, penalty=penalty, solver=solver, random_state=0)\n",
    "\n",
    "    lr.fit(X_train_merged, y_train)\n",
    "    f1 = f1_score(y_val, lr.predict(X_val_merged), average='weighted')\n",
    "    \n",
    "    # Check if score is the best\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = {'C': C, 'penalty': penalty, 'solver': solver}\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Use the best parameter combination found\n",
    "print(\"Best parameters found:\", best_params)\n",
    "best_lr = LogisticRegression(**best_params, random_state=0)\n",
    "best_lr.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_pred = best_lr.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters:\", best_lr.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, lr_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, lr_pred))\n",
    "\n",
    "f1 = f1_score(y_val, lr_pred, average='weighted')\n",
    "print(\"F1 score on validation set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f1f3bb-0fac-44fc-be60-dc9bd9e0752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.8594296203352352 ; for: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d73222-8c24-4c8d-a824-b035c6b0873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one: F1 score on validation set: 0.6115891085889048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd226f-9b73-41bd-a448-1a0963513e5c",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8347d49-0637-497b-ba3c-5abba3612964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [08:12<00:00, 20.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "F1 score on validation set with best parameters: 0.7125480153649167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.81      1135\n",
      "           1       0.46      0.29      0.36       427\n",
      "\n",
      "    accuracy                           0.71      1562\n",
      "   macro avg       0.61      0.58      0.59      1562\n",
      "weighted avg       0.68      0.71      0.69      1562\n",
      "\n",
      "Confusion Matrix:\n",
      "[[989 146]\n",
      " [303 124]]\n",
      "F1 score on validation set: 0.6894710596358977\n"
     ]
    }
   ],
   "source": [
    "# Values for grid search\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 5, 7],     # nº of neighbors\n",
    "    'weights': ['uniform', 'distance'],     # Weight function used \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],     # Algorithm used \n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar\n",
    "total_combinations = len(parameters['n_neighbors']) * len(parameters['weights']) * len(parameters['algorithm'])\n",
    "pbar = tqdm(total=total_combinations)\n",
    "\n",
    "# Iterate over all combinations of parameters\n",
    "for n_neighbors, weights, algorithm in product(parameters['n_neighbors'], parameters['weights'], parameters['algorithm']):\n",
    "\n",
    "    pbar.update(1)\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n",
    "    \n",
    "    knn.fit(X_train_merged, y_train)\n",
    "    knn_pred = knn.predict(X_val_merged)\n",
    "    \n",
    "    f1 = f1_score(y_val, knn_pred, average='weighted')\n",
    "    \n",
    "    # Check if score is the best\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = {'n_neighbors': n_neighbors, 'weights': weights, 'algorithm': algorithm}\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Use the best model found\n",
    "print(\"Best parameters found:\", best_params)\n",
    "best_knn = KNeighborsClassifier(**best_params)\n",
    "best_knn.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_pred = best_knn.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters:\", best_knn.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, knn_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, knn_pred))\n",
    "\n",
    "f1 = f1_score(y_val, knn_pred, average='weighted')\n",
    "print(\"F1 score on validation set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cc6482-7fd0-4591-a4dc-5569467a9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.7863375246559777 ; for: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc783cb-4b80-41e7-bd15-21c654cf33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one: F1 score on validation set: 0.6894710596358977"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560e72a-cbdf-4a1f-bf93-4deb3cc4e538",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9646f9-9885-4e72-82a1-5e3da5172c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 17%|█▋        | 3/18 [00:12<01:06,  4.45s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 28%|██▊       | 5/18 [00:28<01:25,  6.55s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 39%|███▉      | 7/18 [00:41<01:10,  6.42s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 50%|█████     | 9/18 [00:53<00:55,  6.14s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 56%|█████▌    | 10/18 [01:00<00:51,  6.42s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 61%|██████    | 11/18 [01:30<01:34, 13.55s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 67%|██████▋   | 12/18 [01:38<01:11, 11.91s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 15/18 [02:14<00:30, 10.12s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 89%|████████▉ | 16/18 [02:20<00:17,  8.93s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 94%|█████████▍| 17/18 [02:57<00:17, 17.32s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "100%|██████████| 18/18 [03:07<00:00, 10.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'hidden_layer_sizes': (2, 2, 2), 'activation': 'relu', 'solver': 'lbfgs'}\n",
      "F1 score on validation set with best parameters: 0.6754161331626121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79      1135\n",
      "           1       0.36      0.24      0.29       427\n",
      "\n",
      "    accuracy                           0.68      1562\n",
      "   macro avg       0.55      0.54      0.54      1562\n",
      "weighted avg       0.64      0.68      0.65      1562\n",
      "\n",
      "Confusion Matrix:\n",
      "[[953 182]\n",
      " [325 102]]\n",
      "F1 score on validation set: 0.6523929374820174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Parameters for grid search\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(2, 2), (5, 5), (2, 2, 2)],    # hidden layers\n",
    "    'activation': ['logistic', 'relu', 'tanh'],    # Activation function\n",
    "    'solver': ['lbfgs', 'sgd'],     # Optimization algorithm\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar\n",
    "total_combinations = len(parameters['hidden_layer_sizes']) * len(parameters['activation']) * len(parameters['solver'])\n",
    "pbar = tqdm(total=total_combinations)\n",
    "\n",
    "# Perform grid search\n",
    "for hidden_layer_sizes, activation, solver in product(parameters['hidden_layer_sizes'], parameters['activation'], parameters['solver']):\n",
    "\n",
    "    pbar.update(1)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, random_state=0)\n",
    "\n",
    "    mlp.fit(X_train_merged, y_train)\n",
    "    mlp_pred = mlp.predict(X_val_merged)\n",
    "\n",
    "    f1 = f1_score(y_val, mlp_pred, average='weighted')\n",
    "    \n",
    "    # Check if best score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'solver': solver}\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Use the best model found by manual search\n",
    "print(\"Best parameters found:\", best_params)\n",
    "best_mlp = MLPClassifier(**best_params, random_state=0)\n",
    "best_mlp.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "mlp_pred = best_mlp.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters:\", best_mlp.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, mlp_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, mlp_pred))\n",
    "\n",
    "f1 = f1_score(y_val, mlp_pred, average='weighted')\n",
    "print(\"F1 score on validation set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c782299-010b-4465-999f-bdb23ac75a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.8607046991130397 ; for: {'hidden_layer_sizes': (2, 2), 'activation': 'tanh', 'solver': 'sgd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7b2f9-ff8c-4a69-a1ee-5ecbd2ff05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one: F1 score on validation set: 0.6523929374820174"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4ee8e-9e4b-4185-9e83-9d26b19514e1",
   "metadata": {},
   "source": [
    "# Extra Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b7adf-ce8f-4741-ac33-fc162a705dc0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a41ba5-54e2-46ae-a80d-bd9f4f4bb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [17:10<00:00, 28.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for Random Forest: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}\n",
      "F1 score on validation set with best parameters for Random Forest: 0.7458386683738797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85      1135\n",
      "           1       0.81      0.09      0.16       427\n",
      "\n",
      "    accuracy                           0.75      1562\n",
      "   macro avg       0.78      0.54      0.51      1562\n",
      "weighted avg       0.76      0.75      0.66      1562\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[1126    9]\n",
      " [ 388   39]]\n",
      "F1 score on validation set for Random Forest: 0.6626234679812726\n"
     ]
    }
   ],
   "source": [
    "# Values for grid search\n",
    "parameters_rf = {\n",
    "    'n_estimators': [100, 200],     # nº of trees\n",
    "    'max_depth': [None, 10, 20],      # max depth\n",
    "    'min_samples_split': [2, 5, 10],      \n",
    "    'min_samples_leaf': [1, 2]     \n",
    "}\n",
    "\n",
    "best_f1_rf = 0\n",
    "best_params_rf = None\n",
    "\n",
    "# Progression bar\n",
    "total_combinations_rf = len(parameters_rf['n_estimators']) * len(parameters_rf['max_depth']) * len(parameters_rf['min_samples_split']) * len(parameters_rf['min_samples_leaf'])\n",
    "pbar_rf = tqdm(total=total_combinations_rf)\n",
    "\n",
    "# Perform grid search\n",
    "for n_estimators, max_depth, min_samples_split, min_samples_leaf in product(parameters_rf['n_estimators'], parameters_rf['max_depth'], parameters_rf['min_samples_split'], parameters_rf['min_samples_leaf']):\n",
    "\n",
    "    pbar_rf.update(1)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=0)\n",
    "    rf.fit(X_train_merged, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_pred = rf.predict(X_val_merged)\n",
    "    f1_rf = f1_score(y_val, rf_pred, average='weighted')\n",
    "    \n",
    "    # Check if it's the best score\n",
    "    if f1_rf > best_f1_rf:\n",
    "        best_f1_rf = f1_rf\n",
    "        best_params_rf = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pbar_rf.close()\n",
    "\n",
    "# Use the best model found by manual search for Random Forest\n",
    "print(\"Best parameters found for Random Forest:\", best_params_rf)\n",
    "best_rf = RandomForestClassifier(**best_params_rf, random_state=0)\n",
    "best_rf.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = best_rf.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters for Random Forest:\", best_rf.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, rf_pred))\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "print(confusion_matrix(y_val, rf_pred))\n",
    "\n",
    "f1_rf = f1_score(y_val, rf_pred, average='weighted')\n",
    "print(\"F1 score on validation set for Random Forest:\", f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d301c7-29ea-41ae-a1da-a2afcb7f54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.8804259327087324 ; for: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49635526-3f85-48b4-a30a-b70fb6055d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one: F1 score on validation set for Random Forest: 0.6626234679812726"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07639de-f038-4001-8ed7-e1f2f082c550",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781a1aa4-7587-49e9-a90f-d1e46e794fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [09:24<00:00, 31.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for SVM: {'C': 10, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "F1 score on validation set with best parameters for SVM: 0.7183098591549296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      1135\n",
      "           1       0.46      0.16      0.24       427\n",
      "\n",
      "    accuracy                           0.72      1562\n",
      "   macro avg       0.60      0.54      0.53      1562\n",
      "weighted avg       0.67      0.72      0.67      1562\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      "[[1053   82]\n",
      " [ 358   69]]\n",
      "F1 score on validation set for SVM: 0.6663234776328816\n"
     ]
    }
   ],
   "source": [
    "parameters_svm = {\n",
    "    'C': [0.1, 1, 10],      # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'],     # Kernel type\n",
    "    'gamma': ['scale', 'auto']      # coefficient\n",
    "}\n",
    "\n",
    "best_f1_svm = 0\n",
    "best_params_svm = None\n",
    "\n",
    "# progression bar\n",
    "total_combinations_svm = len(parameters_svm['C']) * len(parameters_svm['kernel']) * len(parameters_svm['gamma'])\n",
    "pbar_svm = tqdm(total=total_combinations_svm)\n",
    "\n",
    "# Doing grid search\n",
    "for C, kernel, gamma in product(parameters_svm['C'], parameters_svm['kernel'], parameters_svm['gamma']):\n",
    "\n",
    "    pbar_svm.update(1)\n",
    "    \n",
    "    svm = SVC(C=C, kernel=kernel, gamma=gamma, random_state=0)\n",
    "    svm.fit(X_train_merged, y_train)\n",
    "    \n",
    "    svm_pred = svm.predict(X_val_merged)\n",
    "    f1_svm = f1_score(y_val, svm_pred, average='weighted')\n",
    "    \n",
    "    if f1_svm > best_f1_svm:\n",
    "        best_f1_svm = f1_svm\n",
    "        best_params_svm = {'C': C, 'kernel': kernel, 'gamma': gamma}\n",
    "\n",
    "pbar_svm.close()\n",
    "\n",
    "# Use the best model found by manual search for SVM\n",
    "best_svm = SVC(**best_params_svm, random_state=0)\n",
    "best_svm.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "svm_pred = best_svm.predict(X_val_merged)\n",
    "\n",
    "print(\"Best parameters found for SVM:\", best_params_svm)\n",
    "print(\"F1 score on validation set with best parameters for SVM:\", best_svm.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, svm_pred))\n",
    "print(\"Confusion Matrix for SVM:\")\n",
    "print(confusion_matrix(y_val, svm_pred))\n",
    "\n",
    "f1_svm = f1_score(y_val, svm_pred, average='weighted')\n",
    "print(\"F1 score on validation set for SVM:\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defa680b-1376-4eac-bc69-d7337ab9cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.850832266325224 ; for: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b63bc-d77a-4f8f-adf0-63e140926b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New one: F1 score on validation set for SVM: 0.6663234776328816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab47627-e474-4d32-a3c0-a9b129eb6c93",
   "metadata": {},
   "source": [
    "## Predictions on Test\n",
    "##### Using model with the best score in validation -> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "738f5760-ec6c-400d-957c-71ddeeed6e00",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Decided to train on the entire dataset for the predictions on test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train_merged, X_val_merged])\n\u001b[0;32m      3\u001b[0m y_train_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_train, y_val])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Use model with best score from validation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    383\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    384\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    385\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    386\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    387\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    388\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    389\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:446\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n\u001b[0;32m    447\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:487\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[1;34m(self, objs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    483\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         )\n\u001b[1;32m--> 487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    489\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Decided to train on the entire dataset for the predictions on test set\n",
    "X_train_combined = pd.concat([X_train_merged, X_val_merged])\n",
    "y_train_combined = pd.concat([y_train, y_val])\n",
    "\n",
    "# Use model with best score from validation\n",
    "best_rf.fit(X_train_combined, y_train_combined)\n",
    "test_predictions = best_rf.predict(test_combined)\n",
    "\n",
    "# Creating the output file\n",
    "predictions_df = pd.DataFrame({'id': test_combined['id'], 'predicted': test_predictions})\n",
    "predictions_df.to_csv('Predictions_XX.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ada96e-7eeb-4847-be78-a5bb472dc1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef285d-bc85-4bf7-b7b7-4d491fcc9cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855764f4-e151-40d6-870e-63ebbe331114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf83f3a-6ee5-4403-83e7-a51b883e89e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
