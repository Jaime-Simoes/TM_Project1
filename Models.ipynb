{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8bc2919-f1e4-426f-9054-26e621901612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237df5c3-c6af-401e-9a9e-9b4e3876c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"combined_representations.npz\", allow_pickle=True)\n",
    "X_train_combined = data[\"X_train\"]\n",
    "X_val_combined = data[\"X_val\"]\n",
    "test_combined = data[\"test\"]\n",
    "y_train = data[\"y_train\"]\n",
    "y_val = data[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5686cd31-0d17-4786-9d2f-b837de19c505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'description': array([[ 0.        ,  0.        ,  0.        , ..., -0.08468467,\n",
       "         0.16710296,  0.057366  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.01306781,\n",
       "         0.13182336,  0.0041255 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.13805758,\n",
       "         0.24629688, -0.0862156 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.13059046,\n",
       "         0.33800852,  0.01264326],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.04177414,\n",
       "         0.33193919,  0.06621849],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.08864344,\n",
       "         0.25635894,  0.10819403]]), 'host_about': array([[ 0.        ,  0.        ,  0.        , ..., -0.04349438,\n",
       "        -0.01102248, -0.00268946],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.07374551,\n",
       "         0.27137006,  0.1386768 ],\n",
       "       [ 0.        ,  0.08407949,  0.08587857, ..., -0.03365872,\n",
       "         0.21961312,  0.08438464],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.1946847 ,\n",
       "         0.15675862,  0.18346868],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.20601346,\n",
       "         0.23005761,  0.04385732],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.17294988,\n",
       "         0.2813098 ,  0.13600118]]), 'comments': array([[ 0.00427015,  0.        ,  0.00483969, ..., -0.09409464,\n",
       "         0.22513477,  0.11371527],\n",
       "       [ 0.0635874 ,  0.        ,  0.07206861, ..., -0.002565  ,\n",
       "         0.20820763,  0.01734475],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00713335,  0.        ,  0.        , ..., -0.13487608,\n",
       "         0.1339764 ,  0.1918412 ],\n",
       "       [ 0.14157702,  0.03877514,  0.0401151 , ..., -0.02844723,\n",
       "         0.32519731,  0.01732454]])}, dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c57e753-24e6-4c7f-9c71-7e3fb930126a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'description': array([[ 0.        ,  0.        ,  0.        , ..., -0.17752816,\n",
       "         0.33020436,  0.11092447],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.01434965,\n",
       "         0.39485991,  0.04780014],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.07215451,\n",
       "         0.19116122,  0.10603562],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.12204272,\n",
       "         0.00810044,  0.0257803 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.15537582,\n",
       "         0.30471598,  0.19891339],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.01584726,\n",
       "         0.248952  ,  0.10495016]]), 'host_about': array([[ 0.        ,  0.        ,  0.        , ..., -0.13266554,\n",
       "         0.21048408,  0.06905448],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.07712197,\n",
       "         0.24841082,  0.07409752],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.19376324,\n",
       "         0.16052756,  0.18207438],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.0065152 ,\n",
       "         0.0102364 ,  0.0006557 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.04803084,\n",
       "         0.04464794,  0.0955646 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.03264376,\n",
       "         0.10649814, -0.0158661 ]]), 'comments': array([[ 0.00285803,  0.0048129 ,  0.00168191, ..., -0.10638714,\n",
       "         0.1157219 ,  0.01919548],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.10787476,\n",
       "         0.22766156,  0.10906438],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.18393014,\n",
       "         0.14378067,  0.18188318],\n",
       "       [ 0.02144933,  0.00523485,  0.00768334, ..., -0.14759525,\n",
       "         0.21525526,  0.16833386]])}, dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4637502c-e231-4774-8993-fd4c8191e286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'description': array([[ 0.        ,  0.        ,  0.        , ..., -0.1268446 ,\n",
       "         0.19595661, -0.0083481 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.04427454,\n",
       "        -0.0050476 , -0.03812569],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.0455008 ,\n",
       "         0.21400927,  0.0660574 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.03801016,\n",
       "         0.34924866,  0.05680282],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.13847188,\n",
       "         0.24170396,  0.12646742],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.01582526,\n",
       "         0.24599232,  0.05336657]]), 'host_about': array([[ 0.        ,  0.        ,  0.        , ..., -0.06807236,\n",
       "        -0.0216408 ,  0.01123832],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.018232  ,\n",
       "         0.03550534, -0.0068904 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.17294988,\n",
       "         0.2813098 ,  0.13600118],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.18166426,\n",
       "         0.26868474,  0.14911759],\n",
       "       [ 0.1012124 ,  0.        ,  0.        , ..., -0.03365872,\n",
       "         0.21961312,  0.08438464],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.16558926,\n",
       "         0.27391624,  0.1944242 ]]), 'comments': array([[ 0.02946376,  0.        ,  0.        , ..., -0.11605344,\n",
       "         0.30263128,  0.08693588],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.16969809,\n",
       "         0.36101518,  0.14888891],\n",
       "       ...,\n",
       "       [ 0.00516077,  0.00294683,  0.00299209, ..., -0.16252409,\n",
       "         0.27819405,  0.20788686],\n",
       "       [ 0.04080732,  0.        ,  0.        , ..., -0.01129192,\n",
       "         0.12156244,  0.0447562 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.06495108,\n",
       "         0.37064032,  0.16123983]])}, dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8c433e-8492-43b8-85f2-44b34b39519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1562,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a07d76-e702-454b-b643-1560e7109963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4686,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512ba27-bdf7-4f69-b05b-f08380e4b533",
   "metadata": {},
   "source": [
    "### Preparing data for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f9eca1-d8b2-4b2d-80c5-c99b2e62e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged feature matrix: (4686, 1800)\n"
     ]
    }
   ],
   "source": [
    "# For X_train_combined\n",
    "\n",
    "train_dict = X_train_combined.item()\n",
    "\n",
    "description_features_train = train_dict['description']\n",
    "host_about_features_train = train_dict['host_about']\n",
    "comments_features_train = train_dict['comments']\n",
    "\n",
    "X_train_merged = np.concatenate((description_features_train, host_about_features_train, comments_features_train), axis=1)\n",
    "print(\"Shape of merged feature matrix:\", X_train_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c769012-d604-48d1-b852-1edec788bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged feature matrix: (1562, 1800)\n"
     ]
    }
   ],
   "source": [
    "# For X_val_combined\n",
    "\n",
    "val_dict = X_val_combined.item()\n",
    "\n",
    "description_features_val = val_dict['description']\n",
    "host_about_features_val = val_dict['host_about']\n",
    "comments_features_val = val_dict['comments']\n",
    "\n",
    "X_val_merged = np.concatenate((description_features_val, host_about_features_val, comments_features_val), axis=1)\n",
    "print(\"Shape of merged feature matrix:\", X_val_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bfb901-e737-4717-9883-9c742c0c1892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged feature matrix: (695, 1800)\n"
     ]
    }
   ],
   "source": [
    "# For test_combined\n",
    "\n",
    "test_dict = test_combined.item()\n",
    "\n",
    "description_features_test = test_dict['description']\n",
    "host_about_features_test = test_dict['host_about']\n",
    "comments_features_test = test_dict['comments']\n",
    "\n",
    "X_test_merged = np.concatenate((description_features_test, host_about_features_test, comments_features_test), axis=1)\n",
    "print(\"Shape of merged feature matrix:\", X_test_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb14b7-15ab-434d-9cf2-be878fa46060",
   "metadata": {},
   "source": [
    "# Models\n",
    "##### Grid Searches are small because that's not the main point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf433c9-1de5-4acb-8bb0-c42da7714461",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f39e3d2-4ea9-40ec-bade-29d7cdd22a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:32<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "F1 score on validation set with best parameters: 0.8553137003841229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1135\n",
      "           1       0.69      0.85      0.76       427\n",
      "\n",
      "    accuracy                           0.86      1562\n",
      "   macro avg       0.81      0.85      0.83      1562\n",
      "weighted avg       0.87      0.86      0.86      1562\n",
      "\n",
      "Confusion Matrix:\n",
      "[[974 161]\n",
      " [ 65 362]]\n",
      "F1 score on validation set: 0.8594296203352352\n"
     ]
    }
   ],
   "source": [
    "# Define values for grid search\n",
    "parameters = {\n",
    "    'C': [0.005, 0.01, 0.05],  # Regularization\n",
    "    'penalty': ['l1', 'l2'],  \n",
    "    'solver': ['liblinear', 'saga'],  # Optimization     \n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar\n",
    "total_combinations = len(parameters['C']) * len(parameters['penalty']) * len(parameters['solver'])\n",
    "pbar = tqdm(total=total_combinations)\n",
    "\n",
    "# Iterate over all combinations of parameters\n",
    "for C, penalty, solver in product(parameters['C'], parameters['penalty'], parameters['solver']):\n",
    "\n",
    "    pbar.update(1)\n",
    "    lr = LogisticRegression(C=C, penalty=penalty, solver=solver, random_state=0)\n",
    "\n",
    "    lr.fit(X_train_merged, y_train)\n",
    "    f1 = f1_score(y_val, lr.predict(X_val_merged), average='weighted')\n",
    "    \n",
    "    # Check if score is the best\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = {'C': C, 'penalty': penalty, 'solver': solver}\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Use the best parameter combination found\n",
    "print(\"Best parameters found:\", best_params)\n",
    "best_lr = LogisticRegression(**best_params, random_state=0)\n",
    "best_lr.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_pred = best_lr.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters:\", best_lr.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, lr_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, lr_pred))\n",
    "\n",
    "f1 = f1_score(y_val, lr_pred, average='weighted')\n",
    "print(\"F1 score on validation set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f1f3bb-0fac-44fc-be60-dc9bd9e0752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.8594296203352352 ; for: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd226f-9b73-41bd-a448-1a0963513e5c",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8347d49-0637-497b-ba3c-5abba3612964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [05:57<00:00, 14.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "F1 score on validation set with best parameters: 0.7797695262483995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      1135\n",
      "           1       0.58      0.72      0.64       427\n",
      "\n",
      "    accuracy                           0.78      1562\n",
      "   macro avg       0.73      0.76      0.74      1562\n",
      "weighted avg       0.80      0.78      0.79      1562\n",
      "\n",
      "Confusion Matrix:\n",
      "[[912 223]\n",
      " [121 306]]\n",
      "F1 score on validation set: 0.7863375246559777\n"
     ]
    }
   ],
   "source": [
    "# Values for grid search\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 5, 7],     # nº of neighbors\n",
    "    'weights': ['uniform', 'distance'],     # Weight function used \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],     # Algorithm used \n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar\n",
    "total_combinations = len(parameters['n_neighbors']) * len(parameters['weights']) * len(parameters['algorithm'])\n",
    "pbar = tqdm(total=total_combinations)\n",
    "\n",
    "# Iterate over all combinations of parameters\n",
    "for n_neighbors, weights, algorithm in product(parameters['n_neighbors'], parameters['weights'], parameters['algorithm']):\n",
    "\n",
    "    pbar.update(1)\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n",
    "    \n",
    "    knn.fit(X_train_merged, y_train)\n",
    "    knn_pred = knn.predict(X_val_merged)\n",
    "    \n",
    "    f1 = f1_score(y_val, knn_pred, average='weighted')\n",
    "    \n",
    "    # Check if score is the best\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = {'n_neighbors': n_neighbors, 'weights': weights, 'algorithm': algorithm}\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Use the best model found\n",
    "print(\"Best parameters found:\", best_params)\n",
    "best_knn = KNeighborsClassifier(**best_params)\n",
    "best_knn.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_pred = best_knn.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters:\", best_knn.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, knn_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, knn_pred))\n",
    "\n",
    "f1 = f1_score(y_val, knn_pred, average='weighted')\n",
    "print(\"F1 score on validation set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cc6482-7fd0-4591-a4dc-5569467a9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.7863375246559777 ; for: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560e72a-cbdf-4a1f-bf93-4deb3cc4e538",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9646f9-9885-4e72-82a1-5e3da5172c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:46<01:42,  8.53s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 39%|███▉      | 7/18 [01:26<03:26, 18.73s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 50%|█████     | 9/18 [01:38<01:48, 12.01s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 56%|█████▌    | 10/18 [01:52<01:40, 12.52s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 12/18 [02:34<01:32, 15.45s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 15/18 [03:20<00:39, 13.26s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 89%|████████▉ | 16/18 [03:30<00:24, 12.29s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 94%|█████████▍| 17/18 [03:58<00:16, 16.84s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "100%|██████████| 18/18 [04:05<00:00, 13.77s/it]C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "100%|██████████| 18/18 [04:32<00:00, 15.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'hidden_layer_sizes': (2, 2), 'activation': 'tanh', 'solver': 'sgd'}\n",
      "F1 score on validation set with best parameters: 0.8572343149807938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      1135\n",
      "           1       0.70      0.83      0.76       427\n",
      "\n",
      "    accuracy                           0.86      1562\n",
      "   macro avg       0.82      0.85      0.83      1562\n",
      "weighted avg       0.87      0.86      0.86      1562\n",
      "\n",
      "Confusion Matrix:\n",
      "[[984 151]\n",
      " [ 72 355]]\n",
      "F1 score on validation set: 0.8607046991130397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaime\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Parameters for grid search\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(2, 2), (5, 5), (2, 2, 2)],    # hidden layers\n",
    "    'activation': ['logistic', 'relu', 'tanh'],    # Activation function\n",
    "    'solver': ['lbfgs', 'sgd'],     # Optimization algorithm\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar\n",
    "total_combinations = len(parameters['hidden_layer_sizes']) * len(parameters['activation']) * len(parameters['solver'])\n",
    "pbar = tqdm(total=total_combinations)\n",
    "\n",
    "# Perform grid search\n",
    "for hidden_layer_sizes, activation, solver in product(parameters['hidden_layer_sizes'], parameters['activation'], parameters['solver']):\n",
    "\n",
    "    pbar.update(1)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, random_state=0)\n",
    "\n",
    "    mlp.fit(X_train_merged, y_train)\n",
    "    mlp_pred = mlp.predict(X_val_merged)\n",
    "\n",
    "    f1 = f1_score(y_val, mlp_pred, average='weighted')\n",
    "    \n",
    "    # Check if best score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'solver': solver}\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Use the best model found by manual search\n",
    "print(\"Best parameters found:\", best_params)\n",
    "best_mlp = MLPClassifier(**best_params, random_state=0)\n",
    "best_mlp.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "mlp_pred = best_mlp.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters:\", best_mlp.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, mlp_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, mlp_pred))\n",
    "\n",
    "f1 = f1_score(y_val, mlp_pred, average='weighted')\n",
    "print(\"F1 score on validation set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c782299-010b-4465-999f-bdb23ac75a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.8607046991130397 ; for: {'hidden_layer_sizes': (2, 2), 'activation': 'tanh', 'solver': 'sgd'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4ee8e-9e4b-4185-9e83-9d26b19514e1",
   "metadata": {},
   "source": [
    "# Extra Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b7adf-ce8f-4741-ac33-fc162a705dc0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a41ba5-54e2-46ae-a80d-bd9f4f4bb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [30:01<00:00, 50.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for Random Forest: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1}\n",
      "F1 score on validation set with best parameters for Random Forest: 0.8783610755441741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      1135\n",
      "           1       0.75      0.84      0.79       427\n",
      "\n",
      "    accuracy                           0.88      1562\n",
      "   macro avg       0.84      0.87      0.85      1562\n",
      "weighted avg       0.88      0.88      0.88      1562\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[1014  121]\n",
      " [  69  358]]\n",
      "F1 score on validation set for Random Forest: 0.8804259327087324\n"
     ]
    }
   ],
   "source": [
    "# Values for grid search\n",
    "parameters_rf = {\n",
    "    'n_estimators': [100, 200],     # nº of trees\n",
    "    'max_depth': [None, 10, 20],      # max depth\n",
    "    'min_samples_split': [2, 5, 10],      \n",
    "    'min_samples_leaf': [1, 2]     \n",
    "}\n",
    "\n",
    "best_f1_rf = 0\n",
    "best_params_rf = None\n",
    "\n",
    "# Progression bar\n",
    "total_combinations_rf = len(parameters_rf['n_estimators']) * len(parameters_rf['max_depth']) * len(parameters_rf['min_samples_split']) * len(parameters_rf['min_samples_leaf'])\n",
    "pbar_rf = tqdm(total=total_combinations_rf)\n",
    "\n",
    "# Perform grid search\n",
    "for n_estimators, max_depth, min_samples_split, min_samples_leaf in product(parameters_rf['n_estimators'], parameters_rf['max_depth'], parameters_rf['min_samples_split'], parameters_rf['min_samples_leaf']):\n",
    "\n",
    "    pbar_rf.update(1)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=0)\n",
    "    rf.fit(X_train_merged, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_pred = rf.predict(X_val_merged)\n",
    "    f1_rf = f1_score(y_val, rf_pred, average='weighted')\n",
    "    \n",
    "    # Check if it's the best score\n",
    "    if f1_rf > best_f1_rf:\n",
    "        best_f1_rf = f1_rf\n",
    "        best_params_rf = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pbar_rf.close()\n",
    "\n",
    "# Use the best model found by manual search for Random Forest\n",
    "print(\"Best parameters found for Random Forest:\", best_params_rf)\n",
    "best_rf = RandomForestClassifier(**best_params_rf, random_state=0)\n",
    "best_rf.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = best_rf.predict(X_val_merged)\n",
    "\n",
    "print(\"F1 score on validation set with best parameters for Random Forest:\", best_rf.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, rf_pred))\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "print(confusion_matrix(y_val, rf_pred))\n",
    "\n",
    "f1_rf = f1_score(y_val, rf_pred, average='weighted')\n",
    "print(\"F1 score on validation set for Random Forest:\", f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d301c7-29ea-41ae-a1da-a2afcb7f54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.8804259327087324 ; for: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07639de-f038-4001-8ed7-e1f2f082c550",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781a1aa4-7587-49e9-a90f-d1e46e794fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [07:18<00:00, 24.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for SVM: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "F1 score on validation set with best parameters for SVM: 0.850832266325224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1135\n",
      "           1       0.68      0.85      0.76       427\n",
      "\n",
      "    accuracy                           0.85      1562\n",
      "   macro avg       0.81      0.85      0.82      1562\n",
      "weighted avg       0.87      0.85      0.86      1562\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      "[[966 169]\n",
      " [ 64 363]]\n",
      "F1 score on validation set for SVM: 0.8553811517151816\n"
     ]
    }
   ],
   "source": [
    "parameters_svm = {\n",
    "    'C': [0.1, 1, 10],      # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'],     # Kernel type\n",
    "    'gamma': ['scale', 'auto']      # coefficient\n",
    "}\n",
    "\n",
    "best_f1_svm = 0\n",
    "best_params_svm = None\n",
    "\n",
    "# progression bar\n",
    "total_combinations_svm = len(parameters_svm['C']) * len(parameters_svm['kernel']) * len(parameters_svm['gamma'])\n",
    "pbar_svm = tqdm(total=total_combinations_svm)\n",
    "\n",
    "# Doing grid search\n",
    "for C, kernel, gamma in product(parameters_svm['C'], parameters_svm['kernel'], parameters_svm['gamma']):\n",
    "\n",
    "    pbar_svm.update(1)\n",
    "    \n",
    "    svm = SVC(C=C, kernel=kernel, gamma=gamma, random_state=0)\n",
    "    svm.fit(X_train_merged, y_train)\n",
    "    \n",
    "    svm_pred = svm.predict(X_val_merged)\n",
    "    f1_svm = f1_score(y_val, svm_pred, average='weighted')\n",
    "    \n",
    "    if f1_svm > best_f1_svm:\n",
    "        best_f1_svm = f1_svm\n",
    "        best_params_svm = {'C': C, 'kernel': kernel, 'gamma': gamma}\n",
    "\n",
    "pbar_svm.close()\n",
    "\n",
    "# Use the best model found by manual search for SVM\n",
    "best_svm = SVC(**best_params_svm, random_state=0)\n",
    "best_svm.fit(X_train_merged, y_train)\n",
    "\n",
    "# Predictions\n",
    "svm_pred = best_svm.predict(X_val_merged)\n",
    "\n",
    "print(\"Best parameters found for SVM:\", best_params_svm)\n",
    "print(\"F1 score on validation set with best parameters for SVM:\", best_svm.score(X_val_merged, y_val))\n",
    "print(classification_report(y_val, svm_pred))\n",
    "print(\"Confusion Matrix for SVM:\")\n",
    "print(confusion_matrix(y_val, svm_pred))\n",
    "\n",
    "f1_svm = f1_score(y_val, svm_pred, average='weighted')\n",
    "print(\"F1 score on validation set for SVM:\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defa680b-1376-4eac-bc69-d7337ab9cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best F1: 0.850832266325224 ; for: {'C': 1, 'kernel': 'rbf', 'gamma': 'scale'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab47627-e474-4d32-a3c0-a9b129eb6c93",
   "metadata": {},
   "source": [
    "## Predictions on Test\n",
    "##### Using model with the best score in validation -> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "738f5760-ec6c-400d-957c-71ddeeed6e00",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Decided to train on the entire dataset for the predictions on test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train_merged, X_val_merged])\n\u001b[0;32m      3\u001b[0m y_train_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_train, y_val])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Use model with best score from validation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    383\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    384\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    385\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    386\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    387\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    388\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    389\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:446\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n\u001b[0;32m    447\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:487\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[1;34m(self, objs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    483\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         )\n\u001b[1;32m--> 487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    489\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Decided to train on the entire dataset for the predictions on test set\n",
    "X_train_combined = pd.concat([X_train_merged, X_val_merged])\n",
    "y_train_combined = pd.concat([y_train, y_val])\n",
    "\n",
    "# Use model with best score from validation\n",
    "best_rf.fit(X_train_combined, y_train_combined)\n",
    "test_predictions = best_rf.predict(test_combined)\n",
    "\n",
    "# Creating the output file\n",
    "predictions_df = pd.DataFrame({'id': test_combined['id'], 'predicted': test_predictions})\n",
    "predictions_df.to_csv('Predictions_XX.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ada96e-7eeb-4847-be78-a5bb472dc1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef285d-bc85-4bf7-b7b7-4d491fcc9cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855764f4-e151-40d6-870e-63ebbe331114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf83f3a-6ee5-4403-83e7-a51b883e89e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
